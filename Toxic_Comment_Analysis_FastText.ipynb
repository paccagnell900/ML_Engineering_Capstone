{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4358a7f",
   "metadata": {
    "id": "e4358a7f"
   },
   "source": [
    "### 2. FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39c3fc",
   "metadata": {
    "id": "4f39c3fc"
   },
   "source": [
    "In this section we wil use an other model developed by Facebook, which is built around the concept of embeddings. The main difference compared to the standard word2vec tecnique is that we will avoid the problem of OOV and word srtructure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2ae2b",
   "metadata": {
    "id": "c5b2ae2b"
   },
   "source": [
    "#### a. Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7f8e1e9",
   "metadata": {
    "id": "f7f8e1e9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from fasttext import train_supervised\n",
    "\n",
    "#Sklearn Library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import re\n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords   # import library for stepword\n",
    "from nltk.stem.porter import PorterStemmer  # import library for Stemming\n",
    "from nltk.stem import WordNetLemmatizer   # import library for lemmattazing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43f99d",
   "metadata": {
    "id": "1c43f99d"
   },
   "source": [
    "#### b. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ddf7ac5c",
   "metadata": {
    "id": "ddf7ac5c",
    "outputId": "9e293828-a336-4d93-dcf4-0d2a73049181"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and Read the two dataset, Train and Test\n",
    "df_train = pd.read_csv(\"/Users/stefano/UDACITY/Data Engeeniring/Capstone/Data/train.csv\")   # used to train our model\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3fb373d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()   # Display the first n rows of our training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2512ddc3",
   "metadata": {
    "id": "2512ddc3"
   },
   "source": [
    "#### c. Pre processing data\n",
    "\n",
    "In this section we will clean and prepare the testing data for FastText. \n",
    "\n",
    "1. we punctuation, digit, etc. \n",
    "\n",
    "2. we normalize text, i.e. stemming and lemmatisation\n",
    "\n",
    "3. we convert the binary labels into __class0__ and __class 1__ as FastText use this vocabulary for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5ab8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for text pre-processing, which is a necessary steps for any NLP algorithm.\n",
    "\n",
    "# inizialize the main function variables\n",
    "def pre_processing_txt(text, stemm=True, lemm=True, text_stopwords=None):\n",
    "    \n",
    "    text = ''.join((word for word in text if not word.isdigit()))    # eliminate all digits from our target text\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())   # Regex text + all text lower capital\n",
    "    \n",
    "    ## Tokenize our target text (convert from string to list)\n",
    "    token_text = text.split()\n",
    "    \n",
    "    ## remove Stopwords (all english vocabulary that is not providing meaning added value)\n",
    "    if text_stopwords is not None:\n",
    "        token_text = [word for word in token_text if word not in \n",
    "                    text_stopwords]\n",
    "                \n",
    "    ## Stemming process (remove -ing, -ly, ...)\n",
    "    if stemm == True:\n",
    "        porter_stemmer = nltk.stem.porter.PorterStemmer()  \n",
    "        token_text = [porter_stemmer.stem(word) for word in token_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        token_text = [lem.lemmatize(word) for word in token_text]\n",
    "            \n",
    "    ## back to text string from list\n",
    "    text = \" \".join(token_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47c9ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f4252b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explan whi the edit made under my usernam hard...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww he match thi background colour im seeming...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man im realli not tri to edit war it just ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i cant make ani real suggest on improv i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir are my hero ani chanc you rememb what ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explan whi the edit made under my usernam hard...      0   \n",
       "1  000103f0d9cfb60f  daww he match thi background colour im seeming...      0   \n",
       "2  000113f07ec002fd  hey man im realli not tri to edit war it just ...      0   \n",
       "3  0001b41b1c6bb37e  more i cant make ani real suggest on improv i ...      0   \n",
       "4  0001d958c54c6e35  you sir are my hero ani chanc you rememb what ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test pre_processing_txt function\n",
    "\n",
    "df_train[\"comment_text\"] = df_train[\"comment_text\"].apply(pre_processing_txt)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4726bd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   id                   comment_text        toxic  \\\n",
      "497  014c96f873db11ff  nazi filth is impolit jan utc  __class__1    \n",
      "\n",
      "    severe_toxic      obscene       threat       insult identity_hate  \n",
      "497  __class__0   __class__0   __class__0   __class__1    __class__0   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_train.loc[[497]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6fdb4d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' THIS IS actually my code but it is super slow\\n\\nlabel_prefix = \"__class__\"\\n\\nfor index, row in df_train.iterrows():\\n    df_train[\"toxic\"] = label_prefix + str(row[\"toxic\"])\\n    df_train[\"severe_toxic\"] = label_prefix + str(row[\"severe_toxic\"])\\n    df_train[\"obscene\"] = label_prefix + str(row[\"obscene\"])\\n    df_train[\"threat\"] = label_prefix + str(row[\"threat\"])\\n    df_train[\"insult\"] = label_prefix + str(row[\"insult\"])\\n    df_train[\"identity_hate\"] = label_prefix + str(row[\"identity_hate\"])\\ndf_train.head()\\n\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' THIS IS actually my code but it is super slow\n",
    "\n",
    "label_prefix = \"__class__\"\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    df_train[\"toxic\"] = label_prefix + str(row[\"toxic\"])\n",
    "    df_train[\"severe_toxic\"] = label_prefix + str(row[\"severe_toxic\"])\n",
    "    df_train[\"obscene\"] = label_prefix + str(row[\"obscene\"])\n",
    "    df_train[\"threat\"] = label_prefix + str(row[\"threat\"])\n",
    "    df_train[\"insult\"] = label_prefix + str(row[\"insult\"])\n",
    "    df_train[\"identity_hate\"] = label_prefix + str(row[\"identity_hate\"])\n",
    "df_train.head()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c2e92d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']   # target columns\n",
    "label_prefix = \"__class__\"   # prefix to be added\n",
    "\n",
    "# for loop to add prefix to each target column\n",
    "for col in df_train[classes]:\n",
    "    df_train[col] = label_prefix + df_train[col].astype(str) + ' '\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05534a",
   "metadata": {
    "id": "7f05534a"
   },
   "source": [
    "#### d. Splitting dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "890f3cd4",
   "metadata": {
    "id": "890f3cd4"
   },
   "outputs": [],
   "source": [
    "#Prepare the dataset to be splitted into Train and Test data\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n",
    "\n",
    "X = df_train.comment_text  #predicotors\n",
    "y = df_train[classes] # independent variable\n",
    "\n",
    "# Split of the dataset. Test size 33% and random seed = 42\n",
    "X_train, X_test = train_test_split(df_train, test_size=0.33, shuffle = True, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997022a",
   "metadata": {
    "id": "4c05c601"
   },
   "source": [
    "#### e. Training the model\n",
    "\n",
    "- as FastText is accepting only .cvs file as input, we cannot use a Multi-Output Classifier;\n",
    "- we will use the train_supervised function (as the comments are alreadzy prelabelled;\n",
    "- as in FastText is not possible to calculate the probability of each comment, we will need to loop trhough the whole dataset to obtain this metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7449e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []   # container for all probability per each comments\n",
    "\n",
    "for i in classes: \n",
    "    model = '/Users/stefano/UDACITY/Data Engeeniring/Capstone/working/model.csv'   # Saving the model\n",
    "    \n",
    "    #Saving to a .csv file the output\n",
    "    X_train[[i, \"comment_text\"]].to_csv(model, index=False, header=None, columns=[i, \"comment_text\"]) \n",
    "    \n",
    "    #Use FastText train_supervised\n",
    "    model = train_supervised(input=model, label=\"__class__\", lr=1.0, epoch=2, loss='ova', wordNgrams=2, dim=100, thread=2, verbose=100)\n",
    "    \n",
    "    \n",
    "    # container for all probability per each comments for validation set\n",
    "    prediction_val = []\n",
    "    \n",
    "    #loop over validation set\n",
    "    for g in X_test[\"comment_text\"].values:\n",
    "        \n",
    "        #Get the prediction per each class\n",
    "        pred_val = model.predict(g, k = 2)[1][1]\n",
    "        \n",
    "        #Append the prediction obtained\n",
    "        prediction_val.append(pred_val)\n",
    "        \n",
    "    #Append all prediction to the first list\n",
    "    prediction.append(prediction_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c1d84935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119105</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>geez are you forget weve alreadi discus whi ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131631</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>carioca rfa thank for your support on my reque...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125326</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>birthday no worri it what i do enjoy ur daytalk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111256</th>\n",
       "      <td>5332799e706665a6</td>\n",
       "      <td>pseudosci categori im assum that thi articl is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83590</th>\n",
       "      <td>dfa7d8f0b4366680</td>\n",
       "      <td>and if such phrase exist it would be provid by...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "119105  7ca72b5b9c688e9e  geez are you forget weve alreadi discus whi ma...   \n",
       "131631  c03f72fd8f8bf54f  carioca rfa thank for your support on my reque...   \n",
       "125326  9e5b8e8fc1ff2e84    birthday no worri it what i do enjoy ur daytalk   \n",
       "111256  5332799e706665a6  pseudosci categori im assum that thi articl is...   \n",
       "83590   dfa7d8f0b4366680  and if such phrase exist it would be provid by...   \n",
       "\n",
       "       toxic severe_toxic obscene threat insult identity_hate  \n",
       "119105    0            0       0      0      0             0   \n",
       "131631    0            0       0      0      0             0   \n",
       "125326    0            0       0      0      0             0   \n",
       "111256    0            0       0      0      0             0   \n",
       "83590     0            0       0      0      0             0   "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "X_test[\"toxic\"] = X_test.toxic.str.replace('__class__' , '')\n",
    "X_test[\"severe_toxic\"] = X_test.severe_toxic.str.replace('__class__' , '')\n",
    "X_test[\"obscene\"] = X_test.obscene.str.replace('__class__' , '')\n",
    "X_test[\"threat\"] = X_test.threat.str.replace('__class__' , '')\n",
    "X_test[\"insult\"] = X_test.insult.str.replace('__class__' , '')\n",
    "X_test[\"identity_hate\"] = X_test.identity_hate.str.replace('__class__' , '')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "10cc2598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.56114891e-01, 7.13142985e-03, 4.74358723e-02, 1.55876123e-03,\n",
       "        9.80893224e-02, 2.16253344e-02],\n",
       "       [1.00000034e-05, 4.68312966e-04, 3.89984576e-04, 1.00000034e-05,\n",
       "        5.98408747e-04, 5.13335632e-04],\n",
       "       [3.62300538e-02, 2.33316235e-03, 2.09742412e-02, 1.00000034e-05,\n",
       "        1.85565669e-02, 1.00000034e-05],\n",
       "       ...,\n",
       "       [1.14356913e-03, 8.39589280e-04, 1.25484320e-03, 1.00000034e-05,\n",
       "        3.18268221e-03, 8.65900831e-04],\n",
       "       [5.29304962e-04, 4.97857109e-04, 1.60784519e-03, 1.00000034e-05,\n",
       "        8.65900831e-04, 1.00000034e-05],\n",
       "       [1.04223099e-03, 3.28306481e-03, 1.65848271e-03, 3.18268221e-03,\n",
       "        1.20637799e-02, 2.99103255e-03]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = X_test[classes].astype(\"int\").to_numpy()\n",
    "\n",
    "all_preds_array = np.transpose(np.array(prediction))\n",
    "all_preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2f75571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_test, y_pred):\n",
    "    auc_roc = []\n",
    "    for i in range(y_test.shape[1]):\n",
    "        aucs.append(roc_auc_score(y_test[:,i],y_pred[:,i]))\n",
    "    return aauc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "db54b618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7737228647064045"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_auc = mean(auc_roc(y_test,all_preds_array))\n",
    "mean_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b665d61a",
   "metadata": {
    "id": "b665d61a"
   },
   "source": [
    "The ROC-AUC has scored 77% which is actually a bit better compared to the 72% of the Forest model we have used in the Beg of Words model. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "244e6029",
    "8258f687",
    "334e87b1",
    "4aed618f",
    "c65ad4e6",
    "e418bc0d",
    "c5b2ae2b",
    "1c43f99d",
    "7f05534a",
    "2512ddc3",
    "4c05c601",
    "a341d187",
    "e75805f1",
    "70954987",
    "c058747d",
    "fa4561ba",
    "704b6a0c",
    "a926c21f",
    "08d4d856",
    "e42d40a8",
    "972abbfc",
    "241ca6b1",
    "41797285",
    "a0f38927"
   ],
   "name": "Toxic Comment Analysis (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
